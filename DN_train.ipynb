{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train Denoising Module: \n",
    "- in this notebook, we train the F-actin for Denoising. \n",
    "- The F-actin image patches goes to Super Resoulation Module. \n",
    "- From the SR output, we extract the primary features as PFE branch. \n",
    "- From the input Image we calculate the Mopire Patterns Features as MPE\n",
    "- The PFE and MPE breanches are concanited together for GT branch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from csbdeep.io import load_training_data\n",
    "from csbdeep.utils import axes_dict, plot_some, plot_history\n",
    "import matplotlib.pyplot as plt\n",
    "from models import Denoiser, Train_RDL_Denoising\n",
    "from loss_functions import mse_ssim, mse_ssim_psnr \n",
    "import tensorflow as tf\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbEvalCallback\n",
    "import numpy as np\n",
    "\n",
    "######  login WANDB #########\n",
    "import wandb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "wandb.init(project=\"F-actin_DN\",name=f\"DN_train_MSE_SSIM_ep_1000_b_64\",config= tf.compat.v1.flags.FLAGS, sync_tensorboard=True)\n",
    "tensorboard_callback = TensorBoard(log_dir=wandb.run.dir)\n",
    "tf.function(jit_compile=True)\n",
    "# tf.config.run_functions_eagerly(True)\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "# tf.debugging.enable_check_numerics()\n",
    "## set up the config for the model\n",
    "\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f'These are the GPUs available and will be used :: \\n {gpus}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../F-actin'\n",
    "den_model_dir = Path(root_dir)/'DNModel' \n",
    "sr_model_dir = Path(root_dir)/'SRModel_700_ready' # provide the path to the SR model\n",
    "Path(den_model_dir).mkdir(exist_ok=True)\n",
    "Path(sr_model_dir).mkdir(exist_ok=True)\n",
    "train_data_file = f'{root_dir}/Train/DN/augmented_F-actin_02_DN.npz'\n",
    "log_dir = \"logs/fitDN/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# for saving the results into output folder\n",
    "output_dir = Path.cwd() / 'DN_Model_plots_and_results'\n",
    "Path(output_dir).mkdir( exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the training data and define the model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multi GOu training\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])\n",
    "\n",
    "with strategy.scope(): \n",
    "\n",
    "    ############### load the data ################\n",
    "    (X,Y), (X_val,Y_val), axes = load_training_data(train_data_file, validation_split=0.1, verbose=True)\n",
    "    print('information about DN model Training data')\n",
    "    print(f'X.shape : {X.shape} ,\\n Y.shape : {Y.shape} ,\\n X_val.shape : {X_val.shape} ,\\n Y_val.shape : {Y_val.shape} ,\\naxes : {axes} ')\n",
    "\n",
    "    c = axes_dict(axes)['C']\n",
    "    n_channel_in, n_channel_out = X.shape[c], Y.shape[c]\n",
    "    print(f'n_channel_in : {n_channel_in} , n_channel_out : {n_channel_out} ')\n",
    "    \n",
    "    #############  pre process the data to fit into the model.  ################\n",
    "    def preprocess_data(X, Y):\n",
    "        # Squeeze the unnecessary dimensions and transpose the axes\n",
    "        X = tf.squeeze(X, axis=-1)\n",
    "        Y = tf.squeeze(Y, axis=-1)\n",
    "        X = tf.transpose(X, perm=[0, 2, 3, 1])\n",
    "        Y = tf.transpose(Y, perm=[0, 2, 3, 1])\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "    X, Y = preprocess_data(X, Y)\n",
    "    X_val, Y_val = preprocess_data(X_val, Y_val)\n",
    "    print('after preprocessing the data \\n')\n",
    "    print(f'X.shape : {X.shape} , Y.shape : {Y.shape} , X_val.shape : {X_val.shape} , Y_val.shape : {Y_val.shape} , axes : {axes} ')\n",
    "\n",
    "    ################# plot some train data ################\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plot_some(tf.transpose(X_val[:5], perm=[0, 3, 1, 2]),tf.transpose(Y_val[:5], perm=[0, 3, 1, 2]))\n",
    "    plt.suptitle('5 example validation patches (top row: source, bottom row: target)')\n",
    "    plt.savefig(f'{output_dir}/DN_train_image_F-actin_02.png', bbox_inches='tight')\n",
    "\n",
    "    ################### Define the Parameters ############################\n",
    "    init_lr = 1e-4\n",
    "    lr_decay_factor =.75\t# Learning rate decay factor\t\n",
    "\n",
    "    batch_size = 32\n",
    "    epochs = 1000\n",
    "    beta_1=0.9\n",
    "    beta_2=0.999\n",
    "    wavelength = 0.488 \n",
    "    excNA = 1.35\n",
    "    dx = 62.6e-3\n",
    "    dy = dx\n",
    "    dxy = dx \n",
    "    scale_gt = 2.0\n",
    "    setupNUM = 0\n",
    "    space = wavelength/excNA/2 # here is teh change = /2\n",
    "    k0mod = 1 / space\n",
    "    napodize = 10\n",
    "    nphases = 3\n",
    "    ndirs = 3\n",
    "    sigma_x = 0.5\n",
    "    sigma_y = 0.5\n",
    "    recalcarrays = 2\n",
    "    ifshowmodamp = 0\n",
    "    otf_path = 'TIRF488_cam1_0_z30_OTF2d.mrc' # the otf from the RDL-Sim package\n",
    "    norders = int((nphases + 1) / 2)\n",
    "    if setupNUM == 0:\n",
    "        k0angle_c = [1.48, 2.5272, 3.5744]\n",
    "        k0angle_g = [0.0908, -0.9564, -2.0036]  \n",
    "    if setupNUM == 1:\n",
    "        k0angle_c = [-1.66, -0.6128, 0.4344]\n",
    "        k0angle_g = [3.2269, 2.1797, 1.1325]      \n",
    "    if setupNUM == 2:\n",
    "        k0angle_c = [1.5708, 2.618, 3.6652]\n",
    "        k0angle_g = [0, -1.0472, -2.0944] \n",
    "    total_data,  height, width, channels = X.shape\n",
    "    print(f'\\n\\n total_data,  height, width, channels : {total_data,  height, width, channels} \\n\\n')\n",
    "\n",
    "    ########### define parameter dictionary ################\n",
    "    parameters = {\n",
    "        'Ny': height,\n",
    "        'Nx': width,\n",
    "        'lr_decay_factor': lr_decay_factor,\n",
    "        'wavelength':wavelength,\n",
    "        'excNA':excNA,\n",
    "        'ndirs':ndirs,\n",
    "        'nphases':nphases,\n",
    "        'init_lr': init_lr,\n",
    "        'ifshowmodamp':ifshowmodamp,\n",
    "        'batch_size': batch_size,\n",
    "        'epochs': epochs,\n",
    "        'beta_1':beta_1,\n",
    "        'beta_2':beta_2,\n",
    "        'scale_gt': scale_gt,\n",
    "        'setupNUM': setupNUM,\n",
    "        'k0angle_c':k0angle_c,\n",
    "        'k0angle_g':k0angle_g,\n",
    "        'recalcarrays':recalcarrays,\n",
    "        'dxy':dxy,\n",
    "        'space':space,\n",
    "        'k0mod':k0mod,\n",
    "        'norders':norders,\n",
    "        'napodize':napodize,\n",
    "        'scale': scale_gt,\n",
    "        'sigma_x': sigma_x,\n",
    "        'sigma_y': sigma_y,\n",
    "        'log_dir': log_dir,\n",
    "        'den_model_dir': den_model_dir,\n",
    "        'sr_model_dir': sr_model_dir,\n",
    "        'otf_path' : otf_path,\n",
    "        'results_path': output_dir        \n",
    "    }\n",
    "    ########### check the SR model and load the model if it is already trained ############\n",
    "    if len(os.listdir(sr_model_dir)) > 0:\n",
    "\n",
    "        with tf.keras.utils.custom_object_scope({'mse_ssim': mse_ssim}):\n",
    "            if len(os.listdir(sr_model_dir)) > 0:\n",
    "                print(f'Loading model from {sr_model_dir}')\n",
    "                Trainingmodel_dfcan = load_model(sr_model_dir)\n",
    "    else:\n",
    "        assert 'DFCAN model has to be trained before training RDL denosier'  \n",
    "\n",
    "\n",
    "    ############### define the DN model and compile the model ################\n",
    "    Trainingmodel_denoise = Denoiser((height, width, nphases))\n",
    "    optimizer = Adam(learning_rate=init_lr, beta_1=beta_1, beta_2=beta_2)\n",
    "    Trainingmodel_denoise.compile(loss=mse_ssim, optimizer=optimizer)\n",
    "\n",
    "    # Trainingmodel_denoise.summary() \n",
    "\n",
    "    tensorboard_callback = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    hrate = callbacks.History()\n",
    "    ## Load the denoising model and Train the RDL denoiser\n",
    "    rdl_denoising = Train_RDL_Denoising(\n",
    "                        srmodel=Trainingmodel_dfcan, \n",
    "                        denmodel=Trainingmodel_denoise,\n",
    "                        loss_fn=mse_ssim,\n",
    "                        optimizer=optimizer,\n",
    "                        parameters = parameters)\n",
    "\n",
    "    # Trainingmodel = load_model(den_model_dir)\n",
    "    #print(f'this is the data being send: data :: {data} , data_val :: {data_val} ')\n",
    "    rdl_denoising.fit(data= data, data_val = data_val)\n",
    "                                 # callbacks=[lrate, hrate, srate, tensorboard_callback, WandbMetricsLogger(), wandb_eval_callback ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "# do the orediction on the validation data\n",
    "_P = rdl_denoising.predict(X_val[:5])\n",
    "print(f'P.shape : {_P.shape} ')\n",
    "\n",
    "\n",
    "plot_some(tf.transpose(X_val[:5], perm=[0, 3, 1, 2]),tf.transpose(Y_val[:5], perm=[0, 3, 1, 2]),tf.transpose(_P, perm=[0, 3, 1, 2]),pmax=99.5)\n",
    "plt.suptitle('5 example validation patches\\n'      \n",
    "             'top row: input (source),  '          \n",
    "             'middle row: target (ground truth),  '\n",
    "             'bottom row: predicted from source')\n",
    "plt.savefig(f'{output_dir}/DN_train_image_prediction.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
