{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load a sample image --> preprocess(chunk) --> prediction(on chunks) --> re-construct the full image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'typing_extensions'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "import mrcfile\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from models import DFCAN  # Assuming this defines your model\n",
    "from loss_functions import mse_ssim\n",
    "import os\n",
    "from csbdeep.data.generate import norm_percentiles, sample_percentiles\n",
    "\n",
    "# Set up paths\n",
    "root_dir = '../F-actin'\n",
    "model_dir = Path(root_dir) / 'SRModel_1400_ready'\n",
    "\n",
    "mrc_file = f'/share/klab/argha/Microtubules/Test/Cell_019/RawSIMData_level_05.mrc'\n",
    "output_dir = Path.cwd() / 'SR_Model_plots_and_results'\n",
    "Path(output_dir).mkdir( exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note:  \n",
    "- library missmatch on typoing extension. reinstall it for prediction.\n",
    "- revert it back for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the model\n",
    "if len(os.listdir(model_dir)) > 0:\n",
    "    print(f\"Loading model from {model_dir}\")\n",
    "    with tf.keras.utils.custom_object_scope({'mse_ssim': mse_ssim}):\n",
    "        trained_model = load_model(model_dir)\n",
    "else:\n",
    "    raise ValueError(\"Model directory is empty. Please check the model path.\")\n",
    "\n",
    "# Load the .mrc image\n",
    "with mrcfile.open(mrc_file, mode='r') as mrc:\n",
    "    full_image = mrc.data\n",
    "\n",
    "# Transform the image to shape [502, 502, 9]\n",
    "full_image = np.transpose(full_image, (1, 2, 0))\n",
    "## have to do the image processing. whats done for creating the train image\n",
    "\n",
    "# Print the full image shape for debugging\n",
    "print(f\"Transformed full image shape: {full_image.shape} :: {full_image.dtype} :: {type(full_image)} : min value: {np.min(full_image)} :: max value: {np.max(full_image)}\")\n",
    "# Transformed full image shape: (502, 502, 9) :: uint16 :: <class 'numpy.ndarray'>\n",
    "\n",
    "## expected train data shape: (TensorShape([495, 128, 128, 9]),\n",
    "\n",
    "# Normalize the image to [0, 1]\n",
    "# full_image = norm_percentiles(full_image, 99.5)\n",
    "# print(f\"Transformed full image shape: {full_image.shape} :: {full_image.dtype} :: {type(full_image)}\")\n",
    "\n",
    "#################  TO DO ###########################\n",
    "# ''' Need to percentile normalize the data according to the dat set creation rules'''\n",
    "\n",
    "# ' PERCENTILE NORMALIZATION FUNCTION'\n",
    "def prctile_norm(x, min_prc=1, max_prc=99.9):\n",
    "    y = (x-np.percentile(x, min_prc))/(np.percentile(x, max_prc)-np.percentile(x, min_prc)+1e-7)\n",
    "    return y\n",
    "\n",
    "full_image_percentile = prctile_norm(full_image, 0, 100)\n",
    "print(f\" full_image_percentile  Transformed full image shape: {full_image_percentile.shape} :: {full_image_percentile .dtype} :: {type(full_image_percentile )} : min value: {np.min(full_image_percentile )} :: max value: {np.max(full_image_percentile )}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "normalized_image = full_image_percentile   # Replace this with your actual image array\n",
    "# normalized_image = percentile_normalize(image)\n",
    "# print(f'normalized_image: {normalized_image.shape} :: {normalized_image.dtype} :: {type(normalized_image)}  min {np.min(normalized_image)} :: max  {np.max(normalized_image)}')\n",
    "\n",
    "## visualioze the image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(normalized_image[...,1])\n",
    "plt.title(f'Normalized Image shape: {normalized_image.shape} \\n :: dtype: {normalized_image.dtype} ::\\n min_value: {np.min(normalized_image)} :: \\nmax_value: {np.max(normalized_image)}')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.savefig(f'{output_dir }/sr_normalized_image.png')\n",
    "plt.show()\n",
    "image=normalized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 1: chunk the images as 128 x 128 x 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def chunk_image(image, chunk_size):\n",
    "\n",
    "    chunks = []\n",
    "    chunk_coords = []\n",
    "    image_height, image_width = image.shape[:2]\n",
    "\n",
    "    # Iterate over the image with steps of chunk_size\n",
    "    for y in range(0, image_height, chunk_size):\n",
    "        for x in range(0, image_width, chunk_size):\n",
    "            #print(y , x)\n",
    "            # Calculate end coordinates\n",
    "            y_end = min(y + chunk_size, image_height)\n",
    "            x_end = min(x + chunk_size, image_width)\n",
    "            #print(y_end, x_end)\n",
    "            if y== 384:\n",
    "              y = 502-128\n",
    "            if x == 384:\n",
    "              x = 502-128\n",
    "\n",
    "\n",
    "            # Extract chunk\n",
    "            chunk = image[y:y_end, x:x_end]\n",
    "            # chunk = prctile_norm(chunk)\n",
    "            #print(chunk.shape)\n",
    "            chunks.append(chunk)\n",
    "            chunk_coords.append((x, y))\n",
    "\n",
    "    return chunks, chunk_coords\n",
    "\n",
    "resized_image = normalized_image\n",
    "\n",
    "chunk_size = 128\n",
    "chunks, chunk_coords = chunk_image(resized_image, chunk_size)\n",
    "print(f'after chunkinh: {len(chunks)} :: {len(chunk_coords)} :: {type(chunks)} {type(chunk_coords)}')\n",
    "chunks= np.array(chunks).astype(np.float32)\n",
    "\n",
    "print(f'chunks: {chunks.shape} :: {chunks.dtype} :: {type(chunks)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the chunks in a grid layout\n",
    "num_chunks = chunks.shape[0]\n",
    "ncols = int(np.ceil(np.sqrt(num_chunks)))\n",
    "nrows = int(np.ceil(num_chunks / ncols))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.suptitle('Chunks')\n",
    "print(f'chunks: {chunks.shape} {type(chunks)} : chunk_coords: {len(chunk_coords)}{type(chunk_coords)} ')\n",
    "for i, (chunk, (x_start, y_start)) in enumerate(zip(chunks, chunk_coords)):\n",
    "    print(f'chunk.shape: {chunk.shape} :: {type(chunk)} , {x_start}, {y_start}')\n",
    "    print(f'min value: {np.min(chunk)} :: max value: {np.max(chunk)} dtype: {chunk.dtype}')\n",
    "    plt.subplot(nrows, ncols, i + 1)\n",
    "    plt.imshow(chunk[...,1])\n",
    "    plt.title(f\"({x_start}, {y_start}):S {chunk.shape}\", fontsize=8)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'{output_dir }/SR_chunk_.png')\n",
    "    # plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2: Upscale each chunk (prediction from SR) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_chunks(chunks, chunk_coords, upscale_factor=2):\n",
    "\n",
    "\n",
    "    upscaled_chunks = []\n",
    "    upscaled_chunk_coords = []\n",
    "    # will be feed into prediction from SR\n",
    "    chunks = np.array(chunks)\n",
    "    print(chunks.shape)\n",
    "    predictions = trained_model.predict(chunks)\n",
    "\n",
    "\n",
    "    print(f'predictions: {predictions.shape} {type(predictions)} {predictions.dtype} min_value: {np.min(predictions)} max_value: {np.max(predictions)}')\n",
    "    predictions=predictions\n",
    "    \n",
    "    for i, pred in enumerate(predictions):\n",
    "        # Convert the image back to the original shape if needed\n",
    "        pred = tf.squeeze(pred, axis=-1)  # Remove the last channel if it's 1\n",
    "        output_path = f'{output_dir }/' + f'predicted_image_numpy{i+1}.tif'\n",
    "        tifffile.imwrite(output_path, pred.numpy())\n",
    "\n",
    "    for i, chunk in enumerate(predictions):\n",
    "        print(f'output of teh prediction each chunk: {chunk.shape}')\n",
    "        pred = tf.squeeze(chunk, axis=-1)\n",
    "        print(f' chunk_pred_shape : {pred.shape}')\n",
    "        \n",
    "        upscaled_chunks.append(pred)\n",
    "\n",
    "        x_start, y_start = chunk_coords[i]\n",
    "        upscaled_chunk_coords.append((x_start * upscale_factor, y_start * upscale_factor))\n",
    "\n",
    "    return upscaled_chunks, upscaled_chunk_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 3: Upscale each chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "upscaled_chunks, upscaled_chunk_coords = upscale_chunks(chunks, chunk_coords)\n",
    "print(f'see teh shapes and data :  {len(upscaled_chunks)} :: {len(upscaled_chunk_coords)} :: {type(upscaled_chunks)} :: {type(upscaled_chunk_coords)}')\n",
    "\n",
    "\n",
    "upscaled_chunks= np.array(upscaled_chunks)\n",
    "# upscaled_chunks_viz = upscaled_chunks.\n",
    "print(f'upscaled_chunks: {upscaled_chunks.shape} {type(upscaled_chunks)} : {upscaled_chunks.dtype} : min_value: {np.min(upscaled_chunks)} max_value : {np.max(upscaled_chunks)}') \n",
    "\n",
    "# Visualize the upscaled chunks in a grid layout\n",
    "num_upscaled_chunks = upscaled_chunks.shape[0]\n",
    "ncols_upscaled = int(np.ceil(np.sqrt(num_upscaled_chunks)))\n",
    "nrows_upscaled = int(np.ceil(num_upscaled_chunks / ncols_upscaled))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.suptitle('256x256 Upscaled Chunks')\n",
    "for i, (upscaled_chunk, (x_start, y_start)) in enumerate(zip(upscaled_chunks, upscaled_chunk_coords)):\n",
    "    print(f'min value: {np.min(upscaled_chunk)} :: max value: {np.max(upscaled_chunk)} dtype:  {upscaled_chunk.dtype}')\n",
    "    plt.subplot(nrows_upscaled, ncols_upscaled, i + 1)\n",
    "    plt.imshow(upscaled_chunk)\n",
    "    plt.title(f'({x_start}, {y_start}):S {upscaled_chunk.shape}', fontsize=8)  # Display coordinates as title\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'{output_dir }/SR_upscaled_chunk.png')\n",
    "    #tifffile.imwrite(f'{output_dir }/prediction _ upscale_chunk _ {i} _ normalized.tif', upscaled_chunk)\n",
    "    # plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Reassemble the upscaled chunks into a 1004x1004 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'resized_image' has the shape (height, width, channels)\n",
    "target_size = 1004\n",
    "channels = 1  # Number of channels in the image\n",
    "\n",
    "# Initialize the final image with zeros\n",
    "final_image = np.zeros((target_size, target_size, channels))\n",
    "\n",
    "for i, (upscaled_chunk, (x_start, y_start)) in enumerate(zip(upscaled_chunks, upscaled_chunk_coords)):\n",
    "    # Ensure the chunk has a third dimension (channels)\n",
    "    if len(upscaled_chunk.shape) == 2:  # Shape is (256, 256)\n",
    "        upscaled_chunk = np.expand_dims(upscaled_chunk, axis=-1)  # Shape becomes (256, 256, 1)\n",
    "\n",
    "    # Now, safely check the number of channels\n",
    "    if upscaled_chunk.shape[2] != channels:\n",
    "        raise ValueError(f\"Chunk has {upscaled_chunk.shape[2]} channels, expected {channels} channels.\")\n",
    "    \n",
    "    x_end = min(x_start + upscaled_chunk.shape[1], target_size)\n",
    "    y_end = min(y_start + upscaled_chunk.shape[0], target_size)\n",
    "\n",
    "    # Ensure that x_end and y_end are valid indices\n",
    "    if x_end > x_start and y_end > y_start:\n",
    "        final_image[y_start:y_end, x_start:x_end, :] = np.maximum(\n",
    "            final_image[y_start:y_end, x_start:x_end, :],\n",
    "            upscaled_chunk[:y_end-y_start, :x_end-x_start, :]\n",
    "        )\n",
    "\n",
    "tifffile.imwrite(f'{output_dir }/prediction _ fullimage.tif', final_image.transpose(2,0,1))\n",
    "\n",
    "# Visualize the final image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(f'Reassembled Image  :: shape :: {final_image.shape} \\n final_imahge:dtype :: {final_image.dtype} :: \\n min_value: {np.min(final_image)} ::\\n max_value: {np.max(final_image)}')\n",
    "plt.imshow(final_image)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.savefig(f'{output_dir }/SR_final_image.png')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
